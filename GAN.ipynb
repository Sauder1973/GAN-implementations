{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ26ucc-Aal6",
        "colab_type": "text"
      },
      "source": [
        "# Problem Definition\n",
        "\n",
        "## Dataset:\n",
        "Consists of all even numbers between zero and 2^n as binary representations\n",
        "\n",
        "Example number 56 is 0111000.\n",
        "\n",
        "This will allow us to test the performance of the generator easily.\n",
        "\n",
        "## Generator\n",
        "\n",
        "takes in random noise and learns to produce only even numbers.\n",
        "\n",
        "Noise Variants:\n",
        "\n",
        "*   Random interger in the range (0,10) for every bit\n",
        "*   A single random interger in the range (0,10) \n",
        "*   A single random floating value in the range (0,1) for every bit\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN-a8ZpabvZg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9GXMWm6bzSn",
        "colab_type": "text"
      },
      "source": [
        "# Convert a number to binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QALlrCKocBnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8445750d-acf7-47a8-bba4-174c8e241056"
      },
      "source": [
        "def get_binary_representation(number, max_number = 128):\n",
        "  number_of_bits = int(math.log(max_number, 2))\n",
        "  code = \"{0:0\" + str(number_of_bits) + \"b}\"\n",
        "  string_representation = code.format(number)\n",
        "  return [int(char) for char in string_representation]\n",
        "\n",
        "\n",
        "get_binary_representation(1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv1553kFcni9",
        "colab_type": "text"
      },
      "source": [
        "# Generate data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6gHCFuIcsjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1c6327d0-30a8-4fe8-fcd7-93889ab98255"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Generates #batch_size even numbers in the range 0 to max_number\n",
        "def generate_training_data(max_number = 128, batch_size = 16):\n",
        "  \n",
        "  data = []\n",
        "  labels = [1] * batch_size\n",
        "  for x in range(batch_size):\n",
        "    data.append(get_binary_representation(random.randrange(0, max_number-1, 2)))\n",
        "\t\n",
        "  return torch.tensor(labels).float(), torch.tensor(data).float()\n",
        "\n",
        "generate_training_data()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " tensor([[1., 0., 1., 0., 1., 0., 0.],\n",
              "         [0., 1., 1., 1., 0., 1., 0.],\n",
              "         [1., 1., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 1., 1., 1., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1., 1., 1., 0.],\n",
              "         [1., 1., 0., 0., 1., 0., 0.],\n",
              "         [1., 1., 0., 0., 1., 1., 0.],\n",
              "         [0., 1., 0., 1., 0., 1., 0.],\n",
              "         [1., 1., 1., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 1., 1., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 1., 1., 1., 1., 0.],\n",
              "         [1., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 1., 1., 1., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH-g2sbcgA8s",
        "colab_type": "text"
      },
      "source": [
        "# Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCO23NK_-vt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Generator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(input_length, input_length)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(input_length, 1)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN3EEnbagOCs",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EuzJkDoCsqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
        "\n",
        "  input_length = int(math.log(max_number, 2))\n",
        "\n",
        "  generator = Generator(input_length)\n",
        "  discriminator = Discriminator(input_length)\n",
        "\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
        "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
        "\n",
        "  loss = nn.BCELoss()\n",
        "\n",
        "  for training_step in range(training_steps):\n",
        "    \n",
        "    # Generator\n",
        "\n",
        "    generator_optimizer.zero_grad()\n",
        "\n",
        "    # Creating noise of #input_length bits\n",
        "    noise = torch.randint(0, 10, size=(batch_size, input_length)).float()\n",
        "    generated_data = generator(noise)\n",
        "\n",
        "    true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
        "    \n",
        "    discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
        "    generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
        "    generator_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Discriminator\n",
        "    '''\n",
        "    It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
        "    but we don't want to update weights of discriminator in that step.\n",
        "\n",
        "    '''\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    \n",
        "    discriminator_output_for_true_data = discriminator(true_data)\n",
        "    true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
        "\n",
        "\n",
        "    '''\n",
        "     It is important to note that when passing in the generated data we want to detach the gradients. \n",
        "     We do this because we are not training the generator we are just focused on the discriminator.\n",
        "    '''\n",
        "\n",
        "    discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
        "    generator_discriminator_loss = loss(\n",
        "        discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
        "    )\n",
        "    discriminator_loss = (\n",
        "        true_discriminator_loss + generator_discriminator_loss\n",
        "    ) / 2\n",
        "    \n",
        "    discriminator_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    if training_step % 10000 == 0:\n",
        "        print(\"Training Steps Completed: \", training_step)\n",
        "\n",
        "  return generator, discriminator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IPPu38bkCA9",
        "colab_type": "text"
      },
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSiBcnWfjGgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5e2a596c-0583-4bde-df8b-77f78458d953"
      },
      "source": [
        "training_parameters = {\n",
        "    \"max_number\": 128,\n",
        "    \"batch_size\": 16,\n",
        "    \"generator_lr\": 0.001,\n",
        "    \"discriminator_lr\": 0.001,\n",
        "}\n",
        "generator, discriminator = train(training_steps = 100000)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Steps Completed:  0\n",
            "Training Steps Completed:  10000\n",
            "Training Steps Completed:  20000\n",
            "Training Steps Completed:  30000\n",
            "Training Steps Completed:  40000\n",
            "Training Steps Completed:  50000\n",
            "Training Steps Completed:  60000\n",
            "Training Steps Completed:  70000\n",
            "Training Steps Completed:  80000\n",
            "Training Steps Completed:  90000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-HA1rGokEpY",
        "colab_type": "text"
      },
      "source": [
        "# Let's see what the generator outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBOrYmZQjgHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5ad47192-8deb-41f5-b92b-5ff22497d5e5"
      },
      "source": [
        "with torch.no_grad():\n",
        "  input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
        "  noise = torch.randint(0, 10, size=(2, input_length)).float()\n",
        "  print(generator(noise))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6.3260e-01, 8.3551e-03, 9.7807e-01, 9.9315e-01, 9.5327e-02, 7.8922e-01,\n",
            "         1.7496e-06],\n",
            "        [6.1768e-01, 6.5238e-04, 9.8244e-01, 9.9712e-01, 2.4946e-03, 9.9868e-01,\n",
            "         2.9306e-09]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoB-LhaZkvXm",
        "colab_type": "text"
      },
      "source": [
        "# So, it generates a float number for every bit - it is basically trying to replicate the training data. \n",
        "\n",
        "# We take a threshold and assign it as 0 OR 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvsBX4kTkbNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_float_representation_to_binary_representation(float_representations, threshold = 0.5):\n",
        "  binary_representations = []\n",
        "  for float_representation in float_representations:\n",
        "    binary_representations.append((float_representation >= threshold).int())\n",
        "     \n",
        "  return binary_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJokAcASmyXa",
        "colab_type": "text"
      },
      "source": [
        "# Convert binary to decimal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWCL8dX-m93L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "694122fd-65fd-4538-b476-118708409949"
      },
      "source": [
        "def convert_binary_to_decimal(n):\n",
        "  n = n.tolist()\n",
        "  n = [str(i) for i in n]\n",
        "  n = \"\".join(n)\n",
        "  return int(n,2)\n",
        "convert_binary_to_decimal(torch.tensor([0,0,1,0])) "
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAHlksmlh9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "8708f18a-742f-42f3-abe1-56b1f8f43d0b"
      },
      "source": [
        "with torch.no_grad():\n",
        "  input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
        "  noise = torch.randint(0, 10, size=( training_parameters[\"batch_size\"], input_length)).float()\n",
        "  binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
        "  for i in range(len(binary_reps)):\n",
        "    binary_rep = binary_reps[i]\n",
        "    print(\"when noise is: \",(noise[i]))\n",
        "    # print(binary_rep)\n",
        "    print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
        "    print(\"---\")\n",
        "\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when noise is:  tensor([4., 9., 7., 6., 3., 4., 5.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([1., 4., 7., 6., 4., 3., 2.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([4., 9., 6., 7., 7., 8., 9.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([8., 7., 4., 2., 5., 4., 8.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([6., 0., 3., 8., 4., 9., 6.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([0., 4., 9., 4., 2., 5., 9.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([1., 6., 2., 3., 9., 6., 9.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([5., 9., 6., 7., 4., 1., 6.])\n",
            "Generated number:  92\n",
            "---\n",
            "when noise is:  tensor([5., 0., 2., 1., 4., 3., 9.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([5., 3., 4., 3., 1., 3., 7.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([8., 5., 7., 7., 5., 5., 5.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([8., 2., 9., 6., 3., 3., 2.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([3., 8., 8., 1., 7., 3., 4.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([6., 5., 7., 8., 4., 8., 6.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([6., 8., 4., 1., 4., 5., 6.])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([4., 8., 5., 8., 2., 2., 7.])\n",
            "Generated number:  92\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XA2o4z7otxm",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "# Let's try with a single digit noise but in that case there are only 10 possibilities of noise and hence in the output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CneemYklFSia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "183ffc9a-4a0f-4bb3-8728-f17392c81544"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Generator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(1, input_length)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(input_length, 1)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)\n",
        "\n",
        "\n",
        "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
        "\n",
        "  input_length = int(math.log(max_number, 2))\n",
        "\n",
        "  generator = Generator(input_length)\n",
        "  discriminator = Discriminator(input_length)\n",
        "\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
        "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
        "\n",
        "  loss = nn.BCELoss()\n",
        "\n",
        "  for training_step in range(training_steps):\n",
        "    \n",
        "    # Generator\n",
        "\n",
        "    generator_optimizer.zero_grad()\n",
        "\n",
        "    # Creating noise of #input_length bits\n",
        "    noise = torch.randint(0, 10, size=(batch_size, 1)).float()\n",
        "    generated_data = generator(noise)\n",
        "\n",
        "    true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
        "    \n",
        "    discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
        "    generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
        "    generator_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Discriminator\n",
        "    '''\n",
        "    It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
        "    but we don't want to update weights of discriminator in that step.\n",
        "\n",
        "    '''\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    \n",
        "    discriminator_output_for_true_data = discriminator(true_data)\n",
        "    true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
        "\n",
        "\n",
        "    '''\n",
        "     It is important to note that when passing in the generated data we want to detach the gradients. \n",
        "     We do this because we are not training the generator we are just focused on the discriminator.\n",
        "    '''\n",
        "\n",
        "    discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
        "    generator_discriminator_loss = loss(\n",
        "        discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
        "    )\n",
        "    discriminator_loss = (\n",
        "        true_discriminator_loss + generator_discriminator_loss\n",
        "    ) / 2\n",
        "    \n",
        "    discriminator_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    if training_step % 1000 == 0:\n",
        "        print(\"Training Steps Completed: \",training_step)\n",
        "\n",
        "  return generator, discriminator\n",
        "\n",
        "training_parameters = {\n",
        "    \"max_number\": 128,\n",
        "    \"batch_size\": 16,\n",
        "    \"generator_lr\": 0.001,\n",
        "    \"discriminator_lr\": 0.001,\n",
        "}\n",
        "generator, discriminator = train(training_steps = 10000)\n",
        "\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Steps Completed:  0\n",
            "Training Steps Completed:  1000\n",
            "Training Steps Completed:  2000\n",
            "Training Steps Completed:  3000\n",
            "Training Steps Completed:  4000\n",
            "Training Steps Completed:  5000\n",
            "Training Steps Completed:  6000\n",
            "Training Steps Completed:  7000\n",
            "Training Steps Completed:  8000\n",
            "Training Steps Completed:  9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhP__rBTrDpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4309c034-136b-4aee-edbe-15334c6fb334"
      },
      "source": [
        "with torch.no_grad():\n",
        "  input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
        "  noise = torch.tensor(range(0,10)).float().unsqueeze(1)\n",
        "  binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
        "  for i in range(len(binary_reps)):\n",
        "    binary_rep = binary_reps[i]\n",
        "    print(\"when noise is: \",int(noise[i][0].item()))\n",
        "    # print(binary_rep)\n",
        "    print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
        "    print(\"---\")\n"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when noise is:  0\n",
            "Generated number:  48\n",
            "---\n",
            "when noise is:  1\n",
            "Generated number:  48\n",
            "---\n",
            "when noise is:  2\n",
            "Generated number:  48\n",
            "---\n",
            "when noise is:  3\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  4\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  5\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  6\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  7\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  8\n",
            "Generated number:  112\n",
            "---\n",
            "when noise is:  9\n",
            "Generated number:  112\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBE1A3uk4RK4",
        "colab_type": "text"
      },
      "source": [
        "# Noise is a floating point number in the range (0,1) for every bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EePEPldH4OwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Generator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(input_length, input_length)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_length):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.linear_layer = nn.Linear(input_length, 1)\n",
        "    self.activation = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear_layer(x)).squeeze(1)\n",
        "\n",
        "\n",
        "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
        "\n",
        "  input_length = int(math.log(max_number, 2))\n",
        "\n",
        "  generator = Generator(input_length)\n",
        "  discriminator = Discriminator(input_length)\n",
        "\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
        "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
        "\n",
        "  loss = nn.BCELoss()\n",
        "\n",
        "  for training_step in range(training_steps):\n",
        "    \n",
        "    # Generator\n",
        "\n",
        "    generator_optimizer.zero_grad()\n",
        "\n",
        "    # Creating noise of #input_length bits\n",
        "    # noise = torch.randint(0, 10, size=(batch_size, input_length)).float()\n",
        "    noise = torch.rand(batch_size, input_length)\n",
        "    generated_data = generator(noise)\n",
        "\n",
        "    true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
        "    \n",
        "    discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
        "    generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
        "    generator_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Discriminator\n",
        "    '''\n",
        "    It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
        "    but we don't want to update weights of discriminator in that step.\n",
        "\n",
        "    '''\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    \n",
        "    discriminator_output_for_true_data = discriminator(true_data)\n",
        "    true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
        "\n",
        "\n",
        "    '''\n",
        "     It is important to note that when passing in the generated data we want to detach the gradients. \n",
        "     We do this because we are not training the generator we are just focused on the discriminator.\n",
        "    '''\n",
        "\n",
        "    discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
        "    generator_discriminator_loss = loss(\n",
        "        discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
        "    )\n",
        "    discriminator_loss = (\n",
        "        true_discriminator_loss + generator_discriminator_loss\n",
        "    ) / 2\n",
        "    \n",
        "    discriminator_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    if training_step % 10000 == 0:\n",
        "        print(\"Training Steps Completed: \", training_step)\n",
        "\n",
        "  return generator, discriminator\n",
        "\n",
        "\n",
        "training_parameters = {\n",
        "    \"max_number\": 128,\n",
        "    \"batch_size\": 16,\n",
        "    \"generator_lr\": 0.001,\n",
        "    \"discriminator_lr\": 0.001,\n",
        "}\n",
        "generator, discriminator = train(training_steps = 100000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkrZcqbv7VZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "02a95c96-5446-49b5-8396-9ad6c8d27e6c"
      },
      "source": [
        "with torch.no_grad():\n",
        "  input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
        "  # noise = torch.randint(0, 10, size=( training_parameters[\"batch_size\"], input_length)).float()\n",
        "  noise = torch.rand(training_parameters[\"batch_size\"], input_length)\n",
        "\n",
        "  binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
        "  for i in range(len(binary_reps)):\n",
        "    binary_rep = binary_reps[i]\n",
        "    print(\"when noise is: \",(noise[i]))\n",
        "    # print(binary_rep)\n",
        "    print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
        "    print(\"---\")\n",
        "\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when noise is:  tensor([0.8106, 0.4741, 0.9136, 0.5192, 0.9628, 0.9755, 0.3203])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.4000, 0.0698, 0.3873, 0.1064, 0.1652, 0.2391, 0.0561])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.8604, 0.2216, 0.6364, 0.6040, 0.9226, 0.5308, 0.1179])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.7048, 0.5569, 0.5531, 0.2525, 0.4057, 0.9604, 0.0672])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.5892, 0.3262, 0.2325, 0.6755, 0.6120, 0.8597, 0.7805])\n",
            "Generated number:  84\n",
            "---\n",
            "when noise is:  tensor([0.6532, 0.9843, 0.7997, 0.1316, 0.8558, 0.8229, 0.4558])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.3727, 0.7715, 0.9897, 0.5178, 0.2221, 0.4936, 0.5569])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.6527, 0.7246, 0.5031, 0.6169, 0.8425, 0.8674, 0.5066])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.3972, 0.7237, 0.0221, 0.8476, 0.5545, 0.9366, 0.7438])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.7147, 0.7588, 0.2031, 0.2264, 0.5539, 0.4764, 0.3830])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.2051, 0.9846, 0.4753, 0.9574, 0.2601, 0.6610, 0.4988])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.9558, 0.7214, 0.2032, 0.9674, 0.3408, 0.4838, 0.1794])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.7053, 0.2525, 0.6357, 0.6992, 0.0576, 0.1351, 0.8888])\n",
            "Generated number:  86\n",
            "---\n",
            "when noise is:  tensor([0.0014, 0.1762, 0.8083, 0.5635, 0.2110, 0.5961, 0.6637])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.0104, 0.8821, 0.4870, 0.9141, 0.6439, 0.8767, 0.7160])\n",
            "Generated number:  70\n",
            "---\n",
            "when noise is:  tensor([0.9394, 0.6367, 0.0669, 0.3111, 0.1585, 0.9910, 0.3169])\n",
            "Generated number:  84\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}