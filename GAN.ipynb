{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJ26ucc-Aal6"
   },
   "source": [
    "# Problem Definition\n",
    "\n",
    "## Dataset:\n",
    "Consists of all even numbers between zero and 2^n as binary representations\n",
    "\n",
    "Example number 56 is 0111000.\n",
    "\n",
    "This will allow us to test the performance of the generator easily.\n",
    "\n",
    "## Generator\n",
    "\n",
    "takes in random noise and learns to produce only even numbers.\n",
    "\n",
    "Noise Variants:\n",
    "\n",
    "*   Random interger in the range (0,10) for every bit\n",
    "*   A single random interger in the range (0,10) \n",
    "*   A single random floating value in the range (0,1) for every bit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EN-a8ZpabvZg"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9GXMWm6bzSn"
   },
   "source": [
    "# Convert a number to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QALlrCKocBnh",
    "outputId": "8445750d-acf7-47a8-bba4-174c8e241056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def get_binary_representation(number, max_number = 128):\n",
    "    number_of_bits = int(math.log(max_number, 2))\n",
    "    code = \"{0:0\" + str(number_of_bits) + \"b}\"\n",
    "    string_representation = code.format(number)\n",
    "    return [int(char) for char in string_representation]\n",
    "\n",
    "\n",
    "get_binary_representation(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv1553kFcni9"
   },
   "source": [
    "# Generate data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "y6gHCFuIcsjU",
    "outputId": "1c6327d0-30a8-4fe8-fcd7-93889ab98255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " tensor([[1., 1., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 1., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 1., 1., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Generates #batch_size even numbers in the range 0 to max_number\n",
    "def generate_training_data(max_number = 128, batch_size = 16):\n",
    "  \n",
    "    data = []\n",
    "    labels = [1] * batch_size\n",
    "    for x in range(batch_size):\n",
    "        data.append(get_binary_representation(random.randrange(0, max_number-1, 2)))\n",
    "\n",
    "    return torch.tensor(labels).float(), torch.tensor(data).float()\n",
    "\n",
    "generate_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aH-g2sbcgA8s"
   },
   "source": [
    "# Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCO23NK_-vt6"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_length, input_length)\n",
    "        self.activation = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_length, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN3EEnbagOCs"
   },
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EuzJkDoCsqp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
    "\n",
    "    input_length = int(math.log(max_number, 2))\n",
    "\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
    "\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for training_step in range(training_steps):\n",
    "    \n",
    "    # Generator\n",
    "\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Creating noise of #input_length bits\n",
    "        noise = torch.randint(0, 10, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
    "\n",
    "        discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
    "        generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Discriminator\n",
    "        '''\n",
    "        It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
    "        but we don't want to update weights of discriminator in that step.\n",
    "\n",
    "        '''\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        discriminator_output_for_true_data = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
    "\n",
    "\n",
    "        '''\n",
    "         It is important to note that when passing in the generated data we want to detach the gradients. \n",
    "         We do this because we are not training the generator we are just focused on the discriminator.\n",
    "        '''\n",
    "\n",
    "        discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(\n",
    "            discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
    "        )\n",
    "        discriminator_loss = (\n",
    "            true_discriminator_loss + generator_discriminator_loss\n",
    "        ) / 2\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        if training_step % 5000 == 0:\n",
    "            print(\"Training Steps Completed: \", training_step)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IPPu38bkCA9"
   },
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "lSiBcnWfjGgb",
    "outputId": "5e2a596c-0583-4bde-df8b-77f78458d953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Steps Completed:  0\n",
      "Training Steps Completed:  5000\n",
      "Training Steps Completed:  10000\n",
      "Training Steps Completed:  15000\n",
      "Training Steps Completed:  20000\n",
      "Training Steps Completed:  25000\n",
      "Training Steps Completed:  30000\n",
      "Training Steps Completed:  35000\n",
      "Training Steps Completed:  40000\n",
      "Training Steps Completed:  45000\n"
     ]
    }
   ],
   "source": [
    "training_parameters = {\n",
    "    \"max_number\": 128,\n",
    "    \"batch_size\": 16,\n",
    "    \"generator_lr\": 0.001,\n",
    "    \"discriminator_lr\": 0.001,\n",
    "}\n",
    "generator, discriminator = train(training_steps = 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-HA1rGokEpY"
   },
   "source": [
    "# Let's see what the generator outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dBOrYmZQjgHw",
    "outputId": "5ad47192-8deb-41f5-b92b-5ff22497d5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.0135e-02, 9.3795e-01, 9.9777e-01, 1.6846e-04, 9.9968e-01, 4.7197e-04,\n",
      "         1.5523e-24],\n",
      "        [6.3910e-03, 1.3177e-01, 9.9992e-01, 7.6263e-05, 9.9939e-01, 2.8300e-06,\n",
      "         1.5848e-23]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
    "    noise = torch.randint(0, 10, size=(2, input_length)).float()\n",
    "    print(generator(noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GoB-LhaZkvXm"
   },
   "source": [
    "# So, it generates a float number for every bit - it is basically trying to replicate the training data. \n",
    "\n",
    "# We take a threshold and assign it as 0 OR 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvsBX4kTkbNm"
   },
   "outputs": [],
   "source": [
    "def convert_float_representation_to_binary_representation(float_representations, threshold = 0.5):\n",
    "    binary_representations = []\n",
    "    for float_representation in float_representations:\n",
    "        binary_representations.append((float_representation >= threshold).int())\n",
    "     \n",
    "    return binary_representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJokAcASmyXa"
   },
   "source": [
    "# Convert binary to decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uWCL8dX-m93L",
    "outputId": "694122fd-65fd-4538-b476-118708409949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_binary_to_decimal(n):\n",
    "    n = n.tolist()\n",
    "    n = [str(i) for i in n]\n",
    "    n = \"\".join(n)\n",
    "    return int(n,2)\n",
    "convert_binary_to_decimal(torch.tensor([0,0,1,0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "hLAHlksmlh9V",
    "outputId": "8708f18a-742f-42f3-abe1-56b1f8f43d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when noise is:  tensor([9., 8., 5., 3., 4., 6., 2.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([8., 7., 7., 0., 2., 1., 0.])\n",
      "Generated number:  20\n",
      "---\n",
      "when noise is:  tensor([0., 4., 1., 6., 2., 8., 7.])\n",
      "Generated number:  116\n",
      "---\n",
      "when noise is:  tensor([9., 9., 3., 7., 6., 4., 6.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([3., 2., 2., 6., 0., 5., 6.])\n",
      "Generated number:  20\n",
      "---\n",
      "when noise is:  tensor([3., 8., 8., 5., 1., 2., 5.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([0., 5., 4., 9., 5., 0., 8.])\n",
      "Generated number:  116\n",
      "---\n",
      "when noise is:  tensor([9., 4., 8., 1., 9., 5., 3.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([4., 2., 7., 8., 5., 1., 2.])\n",
      "Generated number:  20\n",
      "---\n",
      "when noise is:  tensor([5., 1., 4., 7., 7., 5., 6.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([7., 8., 4., 9., 6., 5., 9.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([0., 5., 0., 5., 1., 9., 8.])\n",
      "Generated number:  116\n",
      "---\n",
      "when noise is:  tensor([8., 8., 2., 6., 2., 9., 5.])\n",
      "Generated number:  52\n",
      "---\n",
      "when noise is:  tensor([9., 2., 6., 2., 8., 2., 4.])\n",
      "Generated number:  20\n",
      "---\n",
      "when noise is:  tensor([0., 6., 0., 4., 5., 3., 9.])\n",
      "Generated number:  116\n",
      "---\n",
      "when noise is:  tensor([8., 2., 9., 9., 5., 2., 5.])\n",
      "Generated number:  20\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
    "    noise = torch.randint(0, 10, size=( training_parameters[\"batch_size\"], input_length)).float()\n",
    "    binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
    "    for i in range(len(binary_reps)):\n",
    "        binary_rep = binary_reps[i]\n",
    "        print(\"when noise is: \",(noise[i]))\n",
    "        # print(binary_rep)\n",
    "        print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
    "        print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-XA2o4z7otxm"
   },
   "source": [
    "---\n",
    "---\n",
    "# Let's try with a single digit noise but in that case there are only 10 possibilities of noise and hence in the output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "CneemYklFSia",
    "outputId": "183ffc9a-4a0f-4bb3-8728-f17392c81544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Steps Completed:  0\n",
      "Training Steps Completed:  5000\n",
      "Training Steps Completed:  10000\n",
      "Training Steps Completed:  15000\n",
      "Training Steps Completed:  20000\n",
      "Training Steps Completed:  25000\n",
      "Training Steps Completed:  30000\n",
      "Training Steps Completed:  35000\n",
      "Training Steps Completed:  40000\n",
      "Training Steps Completed:  45000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(1, input_length)\n",
    "        self.activation = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_length, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)\n",
    "\n",
    "\n",
    "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
    "\n",
    "    input_length = int(math.log(max_number, 2))\n",
    "\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
    "\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for training_step in range(training_steps):\n",
    "    \n",
    "    # Generator\n",
    "\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Creating noise of #input_length bits\n",
    "        noise = torch.randint(0, 10, size=(batch_size, 1)).float()\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
    "\n",
    "        discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
    "        generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Discriminator\n",
    "        '''\n",
    "        It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
    "        but we don't want to update weights of discriminator in that step.\n",
    "\n",
    "        '''\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        discriminator_output_for_true_data = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
    "\n",
    "\n",
    "        '''\n",
    "         It is important to note that when passing in the generated data we want to detach the gradients. \n",
    "         We do this because we are not training the generator we are just focused on the discriminator.\n",
    "        '''\n",
    "\n",
    "        discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(\n",
    "            discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
    "        )\n",
    "        discriminator_loss = (\n",
    "            true_discriminator_loss + generator_discriminator_loss\n",
    "        ) / 2\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        if training_step % 5000 == 0:\n",
    "            print(\"Training Steps Completed: \",training_step)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "training_parameters = {\n",
    "    \"max_number\": 128,\n",
    "    \"batch_size\": 16,\n",
    "    \"generator_lr\": 0.001,\n",
    "    \"discriminator_lr\": 0.001,\n",
    "}\n",
    "generator, discriminator = train(training_steps = 50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "bhP__rBTrDpP",
    "outputId": "4309c034-136b-4aee-edbe-15334c6fb334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when noise is:  0\n",
      "Generated number:  92\n",
      "---\n",
      "when noise is:  1\n",
      "Generated number:  92\n",
      "---\n",
      "when noise is:  2\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  3\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  4\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  5\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  6\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  7\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  8\n",
      "Generated number:  108\n",
      "---\n",
      "when noise is:  9\n",
      "Generated number:  108\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
    "    noise = torch.tensor(range(0,10)).float().unsqueeze(1)\n",
    "    binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
    "    for i in range(len(binary_reps)):\n",
    "        binary_rep = binary_reps[i]\n",
    "        print(\"when noise is: \",int(noise[i][0].item()))\n",
    "        # print(binary_rep)\n",
    "        print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBE1A3uk4RK4"
   },
   "source": [
    "# Noise is a floating point number in the range (0,1) for every bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EePEPldH4OwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Steps Completed:  0\n",
      "Training Steps Completed:  5000\n",
      "Training Steps Completed:  10000\n",
      "Training Steps Completed:  15000\n",
      "Training Steps Completed:  20000\n",
      "Training Steps Completed:  25000\n",
      "Training Steps Completed:  30000\n",
      "Training Steps Completed:  35000\n",
      "Training Steps Completed:  40000\n",
      "Training Steps Completed:  45000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_length, input_length)\n",
    "        self.activation = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_length, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear_layer(x)).squeeze(1)\n",
    "\n",
    "\n",
    "def train(max_number = 128, batch_size = 16, training_steps = 1000):\n",
    "\n",
    "    input_length = int(math.log(max_number, 2))\n",
    "\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr = training_parameters[\"generator_lr\"])\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = training_parameters[\"discriminator_lr\"])\n",
    "\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for training_step in range(training_steps):\n",
    "    \n",
    "        # Generator\n",
    "\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Creating noise of #input_length bits\n",
    "        # noise = torch.randint(0, 10, size=(batch_size, input_length)).float()\n",
    "        noise = torch.rand(batch_size, input_length)\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        true_labels, true_data = generate_training_data(max_number, batch_size=batch_size)\n",
    "\n",
    "        discriminator_output_on_generated_data = discriminator(generated_data).view(batch_size)\n",
    "        generator_loss = loss(discriminator_output_on_generated_data, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Discriminator\n",
    "        '''\n",
    "        It is important to zero.grad() the gradients for discriminator since in the above steps gradients were accumulated \n",
    "        but we don't want to update weights of discriminator in that step.\n",
    "\n",
    "        '''\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        discriminator_output_for_true_data = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(discriminator_output_for_true_data, true_labels)\n",
    "\n",
    "\n",
    "        '''\n",
    "         It is important to note that when passing in the generated data we want to detach the gradients. \n",
    "         We do this because we are not training the generator we are just focused on the discriminator.\n",
    "        '''\n",
    "\n",
    "        discriminator_output_for_generated_data = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(\n",
    "            discriminator_output_for_generated_data, torch.zeros(batch_size)\n",
    "        )\n",
    "        discriminator_loss = (\n",
    "            true_discriminator_loss + generator_discriminator_loss\n",
    "        ) / 2\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        if training_step % 5000 == 0:\n",
    "            print(\"Training Steps Completed: \", training_step)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "training_parameters = {\n",
    "    \"max_number\": 128,\n",
    "    \"batch_size\": 16,\n",
    "    \"generator_lr\": 0.001,\n",
    "    \"discriminator_lr\": 0.001,\n",
    "}\n",
    "generator, discriminator = train(training_steps = 50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "QkrZcqbv7VZ7",
    "outputId": "02a95c96-5446-49b5-8396-9ad6c8d27e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when noise is:  tensor([0.6225, 0.0369, 0.7624, 0.1954, 0.8584, 0.1222, 0.3718])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.9042, 0.2575, 0.4305, 0.1611, 0.4935, 0.0673, 0.9583])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.6216, 0.8725, 0.2764, 0.2445, 0.5246, 0.4450, 0.2369])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.9486, 0.5285, 0.8126, 0.5933, 0.2355, 0.3959, 0.4888])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.7753, 0.5874, 0.7034, 0.6238, 0.4979, 0.8341, 0.1090])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.3145, 0.1065, 0.9520, 0.9779, 0.0270, 0.0555, 0.0814])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.7220, 0.7835, 0.7316, 0.4158, 0.6531, 0.6581, 0.5803])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.0975, 0.4882, 0.4739, 0.5245, 0.9468, 0.8146, 0.9106])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.4927, 0.4466, 0.7148, 0.0619, 0.3439, 0.9166, 0.0020])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.9709, 0.7968, 0.3220, 0.7239, 0.1959, 0.4814, 0.0524])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.8788, 0.1927, 0.6214, 0.3857, 0.9248, 0.0204, 0.8762])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.7181, 0.1565, 0.1154, 0.9557, 0.3979, 0.5582, 0.5346])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.7401, 0.4743, 0.2261, 0.3045, 0.8535, 0.3286, 0.3329])\n",
      "Generated number:  66\n",
      "---\n",
      "when noise is:  tensor([0.4158, 0.1910, 0.9442, 0.5730, 0.3762, 0.6067, 0.0403])\n",
      "Generated number:  98\n",
      "---\n",
      "when noise is:  tensor([0.7944, 0.3370, 0.2856, 0.5105, 0.8606, 0.4428, 0.0581])\n",
      "Generated number:  102\n",
      "---\n",
      "when noise is:  tensor([0.3438, 0.2984, 0.2855, 0.5248, 0.3256, 0.2275, 0.0270])\n",
      "Generated number:  98\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_length = int(math.log(training_parameters[\"max_number\"], 2))\n",
    "    # noise = torch.randint(0, 10, size=( training_parameters[\"batch_size\"], input_length)).float()\n",
    "    noise = torch.rand(training_parameters[\"batch_size\"], input_length)\n",
    "\n",
    "    binary_reps = convert_float_representation_to_binary_representation(generator(noise))\n",
    "    for i in range(len(binary_reps)):\n",
    "        binary_rep = binary_reps[i]\n",
    "        print(\"when noise is: \",(noise[i]))\n",
    "        # print(binary_rep)\n",
    "        print(\"Generated number: \", convert_binary_to_decimal(binary_rep))\n",
    "        print(\"---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
